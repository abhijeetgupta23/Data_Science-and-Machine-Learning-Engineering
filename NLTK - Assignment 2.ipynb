{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from nltk) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'will', 'would','should']\n",
    "cfdist = nltk.ConditionalFreqDist((word, file) \n",
    "                                  for file in gutenberg.fileids() \n",
    "                                  for word in gutenberg.words(file) \n",
    "                                  if word in modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>would</th>\n",
       "      <th>could</th>\n",
       "      <th>might</th>\n",
       "      <th>will</th>\n",
       "      <th>may</th>\n",
       "      <th>should</th>\n",
       "      <th>can</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>austen-emma.txt</td>\n",
       "      <td>815</td>\n",
       "      <td>825</td>\n",
       "      <td>322</td>\n",
       "      <td>559</td>\n",
       "      <td>213</td>\n",
       "      <td>366</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>austen-persuasion.txt</td>\n",
       "      <td>351</td>\n",
       "      <td>444</td>\n",
       "      <td>166</td>\n",
       "      <td>162</td>\n",
       "      <td>87</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>507</td>\n",
       "      <td>568</td>\n",
       "      <td>215</td>\n",
       "      <td>354</td>\n",
       "      <td>169</td>\n",
       "      <td>228</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bible-kjv.txt</td>\n",
       "      <td>443</td>\n",
       "      <td>165</td>\n",
       "      <td>475</td>\n",
       "      <td>3807</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>blake-poems.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bryant-stories.txt</td>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>burgess-busterbrown.txt</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>carroll-alice.txt</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chesterton-ball.txt</td>\n",
       "      <td>139</td>\n",
       "      <td>117</td>\n",
       "      <td>69</td>\n",
       "      <td>198</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chesterton-brown.txt</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>71</td>\n",
       "      <td>111</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chesterton-thursday.txt</td>\n",
       "      <td>116</td>\n",
       "      <td>148</td>\n",
       "      <td>71</td>\n",
       "      <td>109</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>edgeworth-parents.txt</td>\n",
       "      <td>503</td>\n",
       "      <td>420</td>\n",
       "      <td>127</td>\n",
       "      <td>517</td>\n",
       "      <td>160</td>\n",
       "      <td>271</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>421</td>\n",
       "      <td>215</td>\n",
       "      <td>183</td>\n",
       "      <td>379</td>\n",
       "      <td>230</td>\n",
       "      <td>181</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>milton-paradise.txt</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>98</td>\n",
       "      <td>161</td>\n",
       "      <td>116</td>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shakespeare-caesar.txt</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shakespeare-hamlet.txt</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>131</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shakespeare-macbeth.txt</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>whitman-leaves.txt</td>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>261</td>\n",
       "      <td>85</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         would  could  might  will   may  should  can\n",
       "austen-emma.txt            815    825    322   559   213     366  270\n",
       "austen-persuasion.txt      351    444    166   162    87     185  100\n",
       "austen-sense.txt           507    568    215   354   169     228  206\n",
       "bible-kjv.txt              443    165    475  3807  1024     768  213\n",
       "blake-poems.txt              3      3      2     3     5       6   20\n",
       "bryant-stories.txt         110    154     23   144    18      38   75\n",
       "burgess-busterbrown.txt     46     56     17    19     3      13   23\n",
       "carroll-alice.txt           70     73     28    24    11      27   57\n",
       "chesterton-ball.txt        139    117     69   198    90      75  131\n",
       "chesterton-brown.txt       132    170     71   111    47      56  126\n",
       "chesterton-thursday.txt    116    148     71   109    56      54  117\n",
       "edgeworth-parents.txt      503    420    127   517   160     271  340\n",
       "melville-moby_dick.txt     421    215    183   379   230     181  220\n",
       "milton-paradise.txt         49     62     98   161   116      55  107\n",
       "shakespeare-caesar.txt      40     18     12   129    35      38   16\n",
       "shakespeare-hamlet.txt      60     26     28   131    56      52   33\n",
       "shakespeare-macbeth.txt     42     15      5    62    30      41   21\n",
       "whitman-leaves.txt          85     49     26   261    85      42   88"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cfdist = pd.DataFrame(cfdist)\n",
    "cfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "will      7130\n",
       "would     3932\n",
       "could     3528\n",
       "should    2496\n",
       "may       2435\n",
       "can       2163\n",
       "might     1938\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal_count = cfdist.sum().sort_values(ascending=False)\n",
    "modal_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent Modal : will\n",
      "\n",
      "\n",
      "Text with maximum count of 'will': bible-kjv.txt\n",
      "\n",
      "\n",
      "Text with minimum count of 'will': blake-poems.txt\n"
     ]
    }
   ],
   "source": [
    "most_frequent_modal = modal_count.index[0]\n",
    "print(\"Most Frequent Modal : \"+ str(most_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(\"Text with maximum count of '\" + str(most_frequent_modal) + \"': \" + cfdist.loc[cfdist[most_frequent_modal]==max(cfdist[most_frequent_modal]),most_frequent_modal].index[0])\n",
    "print(\"\\n\")\n",
    "print(\"Text with minimum count of '\" + str(most_frequent_modal) + \"': \" + cfdist.loc[cfdist[most_frequent_modal]==min(cfdist[most_frequent_modal]),most_frequent_modal].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Frequent Modal : might\n",
      "\n",
      "\n",
      "Text with maximum count of 'might': bible-kjv.txt\n",
      "\n",
      "\n",
      "Text with minimum count of 'might': blake-poems.txt\n"
     ]
    }
   ],
   "source": [
    "least_frequent_modal = modal_count.index[-1]\n",
    "print(\"Least Frequent Modal : \"+ str(least_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(\"Text with maximum count of '\" + str(least_frequent_modal) + \"': \" + cfdist.loc[cfdist[least_frequent_modal]==max(cfdist[least_frequent_modal]),least_frequent_modal].index[0])\n",
    "print(\"\\n\")\n",
    "print(\"Text with minimum count of '\" + str(least_frequent_modal) + \"': \" + cfdist.loc[cfdist[least_frequent_modal]==min(cfdist[least_frequent_modal]),least_frequent_modal].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 =  nltk.Text(nltk.corpus.gutenberg.words('bible-kjv.txt'))\n",
    "text2 =  nltk.Text(nltk.corpus.gutenberg.words('blake-poems.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 3836 matches:\n",
      "ood that the man should be alone ; I will make him an help meet for him . 2 : \n",
      " the days of thy life : 3 : 15 And I will put enmity between thee and the woma\n",
      " . 3 : 16 Unto the woman he said , I will greatly multiply thy sorrow and thy \n",
      " heart . 6 : 7 And the LORD said , I will destroy man whom I have created from\n",
      "ence through them ; and , behold , I will destroy them with the earth . 6 : 14\n",
      "rth shall die . 6 : 18 But with thee will I establish my covenant ; and thou s\n",
      "h . 7 : 4 For yet seven days , and I will cause it to rain upon the earth fort\n",
      "ry living substance that I have made will I destroy from off the face of the e\n",
      "; and the LORD said in his heart , I will not again curse the ground any more \n",
      "art is evil from his youth ; neither will I again smite any more every thing l\n",
      " And surely your blood of your lives will I require ; at the hand of every bea\n",
      "require ; at the hand of every beast will I require it , and at the hand of ma\n",
      "at the hand of every man ' s brother will I require the life of man . 9 : 6 Wh\n",
      "ry beast of the earth . 9 : 11 And I will establish my covenant with you , nei\n",
      " be seen in the cloud : 9 : 15 And I will remember my covenant , which is betw\n",
      "he bow shall be in the cloud ; and I will look upon it , that I may remember t\n",
      "s they begin to do : and now nothing will be restrained from them , which they\n",
      "ather ' s house , unto a land that I will shew thee : 12 : 2 And I will make o\n",
      "that I will shew thee : 12 : 2 And I will make of thee a great nation , and I \n",
      " make of thee a great nation , and I will bless thee , and make thy name great\n",
      "u shalt be a blessing : 12 : 3 And I will bless them that bless thee , and cur\n",
      "nto Abram , and said , Unto thy seed will I give this land : and there builded\n",
      "ll say , This is his wife : and they will kill me , but they will save thee al\n",
      "e : and they will kill me , but they will save thee alive . 12 : 13 Say , I pr\n",
      "hou wilt take the left hand , then I will go to the right ; or if thou depart \n",
      "None\n",
      "\n",
      "\n",
      "Displaying 3 of 3 matches:\n",
      "arn ' d the heat to bear , The cloud will vanish , we shall hear His voice , S\n",
      "lver hair , And be like him , and he will then love me . THE BLOSSOM Merry , m\n",
      "alone nor or itself : fear not and I will call , The weak worm from its lowly \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.concordance(most_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(text2.concordance(most_frequent_modal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 475 matches:\n",
      "aidst thou , She is my sister ? so I might have taken her to me to wife : now t\n",
      "as not able to bear them , that they might dwell together : for their substance\n",
      "raham said unto God , O that Ishmael might live before thee ! 17 : 19 And God s\n",
      "ast done unto us ? one of the people might lightly have lien with thy wife , an\n",
      "And Laban said , Behold , I would it might be according to thy word . 30 : 35 A\n",
      "he cattle in the gutters , that they might conceive among the rods . 30 : 42 Bu\n",
      " me ; and didst not tell me , that I might have sent thee away with mirth , and\n",
      "heir riches were more than that they might dwell together ; and the land wherei\n",
      ", and lay no hand upon him ; that he might rid him out of their hands , to deli\n",
      "y themselves : because the Egyptians might not eat bread with the Hebrews ; for\n",
      " Reuben , thou art my firstborn , my might , and the beginning of my strength ,\n",
      "d the heart of his servants , that I might shew these my signs before him : 10 \n",
      "e urgent upon the people , that they might send them out of the land in haste ;\n",
      "o couple the tent together , that it might be one . 36 : 19 And he made a cover\n",
      " ephod with a lace of blue , that it might be above the curious girdle of the e\n",
      "the ephod , and that the breastplate might not be loosed from the ephod ; as th\n",
      " in ward , that the mind of the LORD might be shewed them . 24 : 13 And the LOR\n",
      "in the sight of the heathen , that I might be their God : I am the LORD . 26 : \n",
      "amilies of the Kohathites , all that might do service in the tabernacle of the \n",
      "of the sons of Gershon , of all that might do service in the tabernacle of the \n",
      "hou broughtest up this people in thy might from among them ;) 14 : 14 And they \n",
      "high places of Baal , that thence he might see the utmost part of the people . \n",
      "d made his heart obstinate , that he might deliver him into thy hand , as appea\n",
      " to thy works , and according to thy might ? 3 : 25 I pray thee , let me go ove\n",
      "you statutes and judgments , that ye might do them in the land whither ye go ov\n",
      "None\n",
      "\n",
      "\n",
      "Displaying 2 of 2 matches:\n",
      "nd weeping in the evening dew ; That might control The starry pole , And fallen\n",
      "he Church to stray . Then the Parson might preach , and drink , and sing , And \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.concordance(least_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(text2.concordance(least_frequent_modal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall and may that to should said have for would do might not but did\n",
      "is when was as hath\n",
      "None\n",
      "\n",
      "\n",
      "have\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.similar(most_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(text2.similar(most_frequent_modal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall may will should would and to not that said god cannot did do\n",
      "must life people name mouth strength\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.similar(least_frequent_modal))\n",
    "print(\"\\n\")\n",
    "print(text2.similar(least_frequent_modal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaugural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt', '2013-Obama.txt', '2017-Trump.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "print(inaugural.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_upper_case = [word.upper() for word in inaugural.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(word for word in inaugural_upper_case if len(word)>7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOVERNMENT      600\n",
       "CITIZENS        247\n",
       "CONSTITUTION    206\n",
       "AMERICAN        163\n",
       "NATIONAL        157\n",
       "               ... \n",
       "PETITIONS         1\n",
       "DISCLOSED         1\n",
       "MANUFACTURER      1\n",
       "SHIPMASTER        1\n",
       "ATTAINING         1\n",
       "Length: 4799, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = pd.Series(fdist).sort_values(ascending=False)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOVERNMENT',\n",
       " 'CITIZENS',\n",
       " 'CONSTITUTION',\n",
       " 'AMERICAN',\n",
       " 'NATIONAL',\n",
       " 'CONGRESS',\n",
       " 'INTERESTS',\n",
       " 'POLITICAL',\n",
       " 'EXECUTIVE',\n",
       " 'PRINCIPLES']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_used_words = list(fdist[:10].index)\n",
    "top10_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn                             # wordnet is a semantically oriented dictionary of English\n",
    "\n",
    "synonym_dict_top10 = {}                                                                                   # blank dictionary\n",
    "\n",
    "for word in top10_used_words:                                                                # traverse through top 10 words\n",
    "    synonym_list = set()                                                                    # create a blank set of synonyms\n",
    "    for synset in wn.synsets(word):               #travese through every word's synset (a collection of synonymous entities)\n",
    "        for lemma in synset.lemma_names():                                           #travese through lemmas of every sysnet\n",
    "            synonym_list.add(lemma.upper())                                    # add lemma in upper case to synonym list/set\n",
    "    synonym_dict_top10[word]=synonym_list          # populate synonym dictionary with key as word, and value as synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOVERNMENT : {'GOVERNMENT', 'POLITICS', 'ADMINISTRATION', 'GOVERNANCE', 'GOVERNMENT_ACTIVITY', 'REGIME', 'AUTHORITIES', 'POLITICAL_SCIENCE', 'GOVERNING'}\n",
      "\n",
      "CITIZENS : {'CITIZEN'}\n",
      "\n",
      "CONSTITUTION : {'MAKEUP', 'US_CONSTITUTION', 'CONSTITUTION_OF_THE_UNITED_STATES', 'CONSTITUTION', 'COMPOSITION', 'ORGANIC_LAW', 'FORMATION', 'ORGANIZATION', 'FUNDAMENTAL_LAW', 'MAKE-UP', 'PHYSICAL_COMPOSITION', 'ORGANISATION', 'U.S._CONSTITUTION', 'UNITED_STATES_CONSTITUTION', 'OLD_IRONSIDES', 'ESTABLISHMENT'}\n",
      "\n",
      "AMERICAN : {'AMERICAN', 'AMERICAN_LANGUAGE', 'AMERICAN_ENGLISH'}\n",
      "\n",
      "NATIONAL : {'SUBJECT', 'INTERNAL', 'NATIONAL', 'INTERIOR', 'HOME'}\n",
      "\n",
      "CONGRESS : {'CONGRESS', 'COPULATION', 'US_CONGRESS', 'COITION', 'CARNAL_KNOWLEDGE', 'SEXUAL_CONGRESS', 'SEXUAL_INTERCOURSE', 'INTERCOURSE', 'U.S._CONGRESS', 'SEX_ACT', 'COITUS', 'RELATION', 'SEXUAL_RELATION', 'UNITED_STATES_CONGRESS'}\n",
      "\n",
      "INTERESTS : {'SAKE', 'CONCERN', 'STAKE', 'PASTIME', 'INVOLVEMENT', 'INTEREST_GROUP', 'MATTER_TO', 'PURSUIT', 'OCCUPY', 'INTEREST', 'INTERESTINGNESS', 'WORRY'}\n",
      "\n",
      "POLITICAL : {'POLITICAL'}\n",
      "\n",
      "EXECUTIVE : {'EXECUTIVE', 'EXECUTIVE_DIRECTOR', 'ADMINISTRATOR'}\n",
      "\n",
      "PRINCIPLES : {'RULE', 'PRECEPT', 'RATIONALE', 'PRINCIPLE'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in synonym_dict_top10.keys():\n",
    "    print(key+\" : \"+str(synonym_dict_top10[key])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GOVERNMENT': 9, 'CITIZENS': 1, 'CONSTITUTION': 16, 'AMERICAN': 3, 'NATIONAL': 5, 'CONGRESS': 14, 'INTERESTS': 12, 'POLITICAL': 1, 'EXECUTIVE': 3, 'PRINCIPLES': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CONSTITUTION'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_synonym_dict_top10 = {} # blank dictionary with key as word, value as synonym count\n",
    "\n",
    "for key in synonym_dict_top10.keys(): # travese through all words\n",
    "    len_synonym_dict_top10[key] = len(synonym_dict_top10[key]) # add to len dictionary the synonym count for a word\n",
    "    \n",
    "print(len_synonym_dict_top10) # print the word-synonym length dictionary\n",
    "\n",
    "max(len_synonym_dict_top10, key=len_synonym_dict_top10.get) # get the word with most number of synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyponym_dict_top10 = {}                                                                                   # blank dictionary\n",
    "for word in top10_used_words:                                                                # traverse through top 10 words\n",
    "    hyponym_list = set()                                                                    # create a blank set of synonyms\n",
    "    for synset in wn.synsets(word):             # travese through every word's synset (a collection of synonymous entities)\n",
    "        for hyponym in synset.hyponyms():#travese through every synset's hyponym (immediate concepts that are more specific)\n",
    "            for lemma in hyponym.lemma_names():                                      #travese through every hyponmyn's lemma\n",
    "                hyponym_list.add(lemma.upper())                               # add lemma in upper case to hyponmyn list/set\n",
    "    hyponym_dict_top10[word]=hyponym_list        # populate hyponmyn dictionary with key as word, and value as hyponmyn list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOVERNMENT : {'STATE_GOVERNMENT', 'PAPACY', 'TOTALITARIAN_STATE', 'REALPOLITIK', 'PUPPET_STATE', 'COURT', 'DOWNING_STREET', 'PRACTICAL_POLITICS', 'AUTHORITARIAN_REGIME', 'BUREAUCRACY', 'FEDERAL_GOVERNMENT', 'EMPIRE', 'STRATOCRACY', 'ANCIEN_REGIME', 'TRUST_BUSTING', 'GEOPOLITICS', 'PONTIFICATE', 'MISRULE', 'LEGISLATING', 'ROYAL_COURT', 'LOCAL_GOVERNMENT', 'LEGISLATION', 'AUTHORITARIAN_STATE', 'PALACE', 'MILITARY_GOVERNMENT', 'PUPPET_GOVERNMENT', 'TOTALITATION_REGIME', 'PUPET_REGIME', 'GOVERNMENT-IN-EXILE', 'STATE', 'LAWMAKING', 'MISGOVERNMENT'}\n",
      "\n",
      "CITIZENS : {'PRIVATE_CITIZEN', 'FREEWOMAN', 'THANE', 'CIVILIAN', 'ACTIVE_CITIZEN', 'REPATRIATE', 'VOTER', 'FREEMAN', 'ELECTOR'}\n",
      "\n",
      "CONSTITUTION : {'COLONISATION', 'UNIONIZATION', 'GENETIC_CONSTITUTION', 'GENOTYPE', 'KARYOTYPE', 'FEDERATION', 'PHENOTYPE', 'UNIONISATION', 'STRUCTURE', 'COLLECTIVISATION', 'COMMUNISATION', 'TEXTURE', 'COLONIZATION', 'GRAIN', 'COMMUNIZATION', 'SETTLEMENT', 'COLLECTIVIZATION'}\n",
      "\n",
      "AMERICAN : {'SOUTH_DAKOTAN', 'LOUISIANIAN', 'YANK', 'GARDEN_STATER', 'YANKEE', 'WASHINGTONIAN', 'HOOSIER', 'BUCKEYE', 'NEW_JERSEYITE', 'HAWAIIAN', 'NEBRASKAN', 'MARYLANDER', 'LOUISIANAN', 'VERMONTER', 'VIRGINIAN', 'SPANISH_AMERICAN', 'MISSISSIPPIAN', 'SOUTH_CAROLINIAN', 'LATINO', 'LATIN_AMERICAN', 'KENTUCKIAN', 'YANKEE-DOODLE', 'MAINER', 'WOLVERINE', 'GRANITE_STATER', 'ALASKAN', 'TARHEEL', 'AFRICAN_AMERICAN', 'NISEI', 'OREGONIAN', 'IOWAN', 'BLACK_VERNACULAR', 'ILLINOISAN', 'BAY_STATER', 'GEORGIAN', 'BEAVER', 'MISSOURIAN', 'HISPANIC_AMERICAN', 'WISCONSINITE', 'NORTH_CAROLINIAN', 'PENNSYLVANIAN', 'BLACK_AMERICAN', 'ARKANSAWYER', 'SOUTHERNER', 'NEVADAN', 'BADGER', 'NORTH_AMERICAN', 'GERMAN_AMERICAN', 'VOLUNTEER', 'APPALACHIAN', 'ALABAMIAN', 'NEW_JERSEYAN', 'AFRO-AMERICAN', 'ASIAN_AMERICAN', 'CAROLINIAN', 'NORTHERNER', 'MICHIGANDER', 'CREOLE', 'BLUEGRASS_STATER', 'INDIANAN', 'AFRICAN-AMERICAN', 'MONTANAN', 'NEW_MEXICAN', 'BLACK_VERNACULAR_ENGLISH', 'BLACK_ENGLISH_VERNACULAR', 'WEST_VIRGINIAN', 'ANGLO-AMERICAN', 'NEW_HAMPSHIRITE', 'DELAWAREAN', 'KANSAN', 'FRANCO-AMERICAN', 'ARIZONIAN', 'CORNHUSKER', 'AFRICAN_AMERICAN_VERNACULAR_ENGLISH', 'TEXAN', 'WEST_INDIAN', 'IDAHOAN', 'RHODE_ISLANDER', 'FLORIDIAN', 'BOSTONIAN', 'TORY', 'ARKANSAN', 'ALABAMAN', 'COLORADAN', 'MESOAMERICAN', 'OHIOAN', 'DELAWARIAN', 'CALIFORNIAN', 'CONNECTICUTER', 'AFRICAN_AMERICAN_ENGLISH', 'KEYSTONE_STATER', 'NEW_ENGLANDER', 'AAVE', 'WYOMINGITE', 'GOPHER', 'HISPANIC', 'ARIZONAN', 'DOWN_EASTER', 'NORTH_DAKOTAN', 'MINNESOTAN', 'UTAHAN', 'OKLAHOMAN', 'SOONER', 'NEW_YORKER', 'PUERTO_RICAN', 'EBONICS', 'SOUTH_AMERICAN', 'BLACK_ENGLISH', 'TENNESSEAN'}\n",
      "\n",
      "NATIONAL : {'CITIZEN', 'COMPATRIOT', 'PATRIOT', 'NATIONALIST'}\n",
      "\n",
      "CONGRESS : {'PENETRATION', 'UNLAWFUL_CARNAL_KNOWLEDGE', 'FUCKING', 'SHTUP', 'SHAG', 'FUCK', 'SCREWING', 'HANK_PANKY', 'PIECE_OF_TAIL', 'NOOKIE', 'ROLL_IN_THE_HAY', 'PIECE_OF_ASS', 'DEFLORATION', 'CRIMINAL_CONGRESS', 'NOOKY', 'SCREW', 'ASS', 'CONTINENTAL_CONGRESS'}\n",
      "\n",
      "INTERESTS : {'CHARISMA', 'PERSONAL_MAGNETISM', 'ENGAGE', 'FEE', 'TRANSFIX', 'INSURABLE_INTEREST', 'SPARE-TIME_ACTIVITY', 'CONCERN', 'SPECIAL_INTEREST', 'BEHALF', 'RIGHT', 'UNDIVIDED_INTEREST', 'VIVIDNESS', 'SIMPLE_INTEREST', 'SIDELINE', 'GRUBSTAKE', 'ENTHUSIASM', 'SHRILLNESS', 'TOPICALITY', 'PURSUIT', 'EQUITY', 'AVOCATION', 'HOBBY', 'COMPOUND_INTEREST', 'SPELLBIND', 'PERSONAL_APPEAL', 'TERMINABLE_INTEREST', 'OCCUPY', 'UNDIVIDED_RIGHT', 'VESTED_INTEREST', 'GRIP', 'FASCINATE', 'NEWS', 'COLOUR', 'BY-LINE', 'ENGROSS', 'REVERSION', 'INTRIGUE', 'SECURITY_INTEREST', 'ABSORB', 'COLOR', 'NEWSWORTHINESS', 'CONTROLLING_INTEREST'}\n",
      "\n",
      "POLITICAL : set()\n",
      "\n",
      "EXECUTIVE : {'TRIUMVIR', 'VICE_PRESIDENT', 'SECRETARY_GENERAL', 'RAINMAKER', 'GOVERNMENT_MINISTER', 'SURGEON_GENERAL', 'CARTER_ADMINISTRATION', 'CLINTON_ADMINISTRATION', 'BUSINESS_EXECUTIVE', 'REAGAN_ADMINISTRATION', 'DIRECTOR_OF_CENTRAL_INTELLIGENCE', 'CORPORATE_EXECUTIVE', 'V.P.', 'DCI', 'PREFECT', 'MINISTER', 'BUSH_ADMINISTRATION', 'COMMISSIONER'}\n",
      "\n",
      "PRINCIPLES : {\"HUYGENS'_PRINCIPLE_OF_SUPERPOSITION\", 'PLEASURE-UNPLEASURE_PRINCIPLE', 'CAVEAT_EMPTOR', 'BASIC_PRINCIPLE', 'PILLAR', 'LE_CHATELIER-BRAUN_PRINCIPLE', 'LOCALIZATION_PRINCIPLE', 'SUPERPOSITION_PRINCIPLE', 'DIALECTICS', 'SUPERPOSITION', 'LOCALIZATION_OF_FUNCTION', 'ACCOUNTING_STANDARD', 'BASICS', \"OCCAM'S_RAZOR\", 'SCRUPLE', \"LE_CHATELIER'S_PRINCIPLE\", \"LE_CHATELIER'S_LAW\", 'MASS_ACTION', 'REALITY_PRINCIPLE', 'YANG', 'VALUE-SYSTEM', 'HELLENISM', 'JUDICIAL_DOCTRINE', 'PRINCIPLE_OF_LIQUID_DISPLACEMENT', \"NAEGELE'S_RULE\", 'HYPOTHETICAL_IMPERATIVE', 'LOCALIZATION', 'PLEASURE-PAIN_PRINCIPLE', 'LOGIC', 'FUNDAMENTALS', 'PLEASURE_PRINCIPLE', 'LOCALISATION', 'CONSERVATION', \"OCKHAM'S_RAZOR\", 'FENG_SHUI', 'PRINCIPLE_OF_PARSIMONY', 'GESTALT_PRINCIPLE_OF_ORGANIZATION', 'MORAL_PRINCIPLE', 'LEGAL_PRINCIPLE', \"GRESHAM'S_LAW\", 'ETHIC', 'LOCALISATION_PRINCIPLE', 'MASS-ACTION_PRINCIPLE', 'LAW_OF_PARSIMONY', 'PRINCIPLE_OF_SUPERPOSITION', 'FUNDAMENTAL_PRINCIPLE', 'KNIGHTLINESS', 'ACCOUNTING_PRINCIPLE', 'INSURRECTIONISM', 'GESTALT_LAW_OF_ORGANIZATION', 'LE_CHATELIER_PRINCIPLE', 'LOCALISATION_OF_FUNCTION', 'CHIVALRY', 'TAO', 'BEDROCK', 'YIN', 'MASS-ENERGY_EQUIVALENCE', 'PRINCIPLE_OF_EQUIVALENCE', 'HIGHER_LAW', 'DICTATE', 'JUDICIAL_PRINCIPLE', 'VALUE_ORIENTATION'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in hyponym_dict_top10.keys():\n",
    "    print(key+\" : \"+str(hyponym_dict_top10[key])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GOVERNMENT': 32, 'CITIZENS': 9, 'CONSTITUTION': 17, 'AMERICAN': 109, 'NATIONAL': 4, 'CONGRESS': 18, 'INTERESTS': 43, 'POLITICAL': 0, 'EXECUTIVE': 18, 'PRINCIPLES': 62}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AMERICAN'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_hyponym_dict_top10 = {}\n",
    "\n",
    "for key in hyponym_dict_top10.keys():\n",
    "    len_hyponym_dict_top10[key] = len(hyponym_dict_top10[key])\n",
    "    \n",
    "print(len_hyponym_dict_top10)\n",
    "\n",
    "max(len_hyponym_dict_top10, key=len_hyponym_dict_top10.get)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dcbe4d",
   "metadata": {},
   "source": [
    "# In this notebook, we mask a word in a text from wikitext, and then use Masked Language Model to unmask the masked word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5698c0",
   "metadata": {},
   "source": [
    "## Loading the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ed6b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (C:/Users/Abhijeet Gupta/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945204b33a224ebd84d311d8132db1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\",'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3475335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][10][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb3107",
   "metadata": {},
   "source": [
    "## Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8273d831",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "text = dataset[\"train\"][10][\"text\"]\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8abf7",
   "metadata": {},
   "source": [
    "## Adding Mask to Sentence - Replaced index-5 Tokenized Tensor with tokenized value of '[MASK]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13eb6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb978495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'battle'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(2321, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f4982",
   "metadata": {},
   "source": [
    "### The word that we are masking is 'battle'. Thus, the model must predict a word similar to 'battle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8662cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(103)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[MASK]', return_tensors=\"pt\")['input_ids'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3086102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'][0][5] = tokenizer('[MASK]', return_tensors=\"pt\")['input_ids'][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22e3df",
   "metadata": {},
   "source": [
    "## Masked Language Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5202734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForMaskedLM.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "with torch.no_grad(): \n",
    "    logits = model(**inputs).logits\n",
    "    \n",
    "# retrieve index of [MASK]\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "\n",
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "tokenizer.decode(predicted_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e3c6a",
   "metadata": {},
   "source": [
    "### The model predicted 'combat' when the masked word was 'battle'. \n",
    "\n",
    "# This seems accurate, as 'battle' and 'combat' are synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f7330",
   "metadata": {},
   "source": [
    "This is an example of Transfer Learning, in which we use pre-trained models such as "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe62330",
   "metadata": {},
   "source": [
    "# Reference :\n",
    "\n",
    "https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
